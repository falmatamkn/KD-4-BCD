{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9783341,"sourceType":"datasetVersion","datasetId":5993931},{"sourceId":12727910,"sourceType":"datasetVersion","datasetId":8044958}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis code tests our work on Breast Cancer Wisconsin (Diagnostic) Data Set (WDBCD) (https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==2.6.4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\n\n#import os\n#print(os.listdir(\"../input\"))\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n%matplotlib inline \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D,Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import utils\n\n\n\n#Import models from scikit learn module:\nfrom sklearn import datasets,metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\n\n#Measuring Time\nimport time\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"epoch=50","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"#load dataset\ndata = pd.read_csv(\"/kaggle/input/wdbc-kd-data/data.csv\",header = 0)\nprint(type(data))\ndata.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing\n## Get classes","metadata":{}},{"cell_type":"code","source":"Y=data.diagnosis\n\nprint(Y.value_counts())\nY.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title('Count of cancer type')\nsns.countplot(x=\"diagnosis\",data=data)\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare and clean the dataset","metadata":{}},{"cell_type":"code","source":"data.isnull().any().describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Remove unwanted info","metadata":{}},{"cell_type":"code","source":"# drop id and unnamed 32 colums from the features\n# we still need diagnosis for further statistics, \n# it will be dropped later\n\ndata.drop(['id','Unnamed: 32'],axis=1,inplace=True)\ndata.info(),","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyse usable data","metadata":{}},{"cell_type":"code","source":"for i in (data.columns[1:6]):\n    plt.subplot(1,2,1)\n    data[i][data['diagnosis']=='B'].plot.hist(alpha=0.5,title=i,color='green')\n    data[i][data['diagnosis']=='M'].plot.hist(alpha=0.5,color='red')\n    plt.legend(['B','M'],loc='upper right')\n    #plt.grid(visible=True)\n    \n    \n    plt.subplot(1,2,2)\n    sns.boxplot(x=\"diagnosis\", y=i, data=data)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Observations*\n1. Mean values of cell like radius, perimeter, area, compactness, concavity,concave points etc can be used in classification of the cancer. Larger values of these parameters tends to show a correlation with malignant tumors.\n2. Mean values of column like texture, smoothness, symmetry or fractual dimension does not show a particular preference of one diagnosis over the other. In any of the histograms there are no noticeable large outliers that warrants further cleanup.","metadata":{}},{"cell_type":"markdown","source":"## Remove input from data","metadata":{}},{"cell_type":"code","source":"#Diagnosis is in index 0, \n#so we start copying from index 1\n#see, I told you we will drop it ;-)\n\ndata.drop('diagnosis',axis=1,inplace=True)\ndata.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlation matrix","metadata":{}},{"cell_type":"code","source":"# Create correlation matrix\ndata.corr()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correlation=data.corr()\n\n# Getting the Upper Triangle of the co-relation matrix\nmatrix = np.triu(correlation)\nplt.figure(figsize=(40,16))\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='copper',mask=matrix)\nplt.title('Correlation between different fearures')\n#plt.savefig(\"cor.svg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get the input (X)","metadata":{}},{"cell_type":"code","source":"#Copying data to X for bravity\nX=data\n\n#for emulating user\ntemp=pd.DataFrame(data=[data.values.tolist()[0]],columns=data.columns.values.tolist())\ndel data\n\n#Verify :-D\nprint(type(X))\nX.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit_transform(X)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca.get_covariance()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We used logarithmic scale in the y-axis becaus the first value is so high\n\nwith plt.style.context('dark_background'):\n    fig=plt.figure(figsize=(10, 6))\n    ax = fig.add_subplot()\n\n    ax.bar(range(30), explained_variance, alpha=0.5, align='center',\n            label='individual explained variance')\n    ax.set_yscale('log')\n    \n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.grid(visible=True)\n    plt.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Thus we can see from the above plot that first three components constitute almost 73% of the variance. Fourth to twenty sixth components has 25% of the data sprad.The remaining component has less than 0.001% of the variance.Hence we can drop from 27 to 30th component(total of 4 features)\n\n","metadata":{}},{"cell_type":"code","source":"pca=PCA(n_components=26)\nX_new=pca.fit_transform(X)\nX_new","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca.get_covariance()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We used logarithmic scale in the y-axis becaus the first value is so high\n\nwith plt.style.context('dark_background'):\n    fig=plt.figure(figsize=(20, 12))\n    ax = fig.add_subplot()\n\n    ax.bar(range(26), explained_variance, alpha=0.5, align='center',\n            label='individual explained variance')\n    ax.set_yscale('log')\n    \n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.grid(visible=True)\n    plt.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X=X_new\n(X.shape, Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convert to one-hot","metadata":{}},{"cell_type":"code","source":"#Check befor conversion\nprint(\"Converting to categorical\")\nprint(\"Before Conversion:\")\nprint(Y.shape)\nprint(type(Y))\n\n\n#Convert to Categorical values\nY = Y.map({'B':0,'M':1})\nY = utils.to_categorical(Y, num_classes=2)\n\n\n#verify shape\nprint(\"After Conversion:\")\nprint(Y.shape)\ntype(Y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting data into training and testing","metadata":{}},{"cell_type":"code","source":"(X.shape, Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train,X_test,y_train,y_test= train_test_split(X,Y,test_size=0.15,stratify=Y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling","metadata":{}},{"cell_type":"code","source":"scaler=StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n(X_train.shape, X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Reshaping","metadata":{}},{"cell_type":"code","source":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape[1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create teacher and student model","metadata":{}},{"cell_type":"code","source":"# Create the teacher\nteacher =keras.Sequential()\nteacher.add(keras.Input(shape=(X_train.shape[1],1)))\nteacher.add(keras.layers.Conv1D(filters=64,kernel_size= 2,activation='relu'))\nteacher.add(keras.layers.BatchNormalization())\nteacher.add(keras.layers.Dropout(0.2))\n        \nteacher.add(keras.layers.Conv1D(448, 2,activation='relu'))\nteacher.add(keras.layers.BatchNormalization())\nteacher.add(keras.layers.Dropout(0.2))\n        \nteacher.add(keras.layers.Flatten())\nteacher.add(keras.layers.Dense(64,activation='relu'))\nteacher.add(keras.layers.Dropout(0.2))\n\nteacher.add(keras.layers.Dense(2,activation='sigmoid'))\n\nteacher.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n\n# Create the student\nstudent = keras.Sequential(\n    [\n        keras.Input(shape=(X_train.shape[1], 1)),\n        layers.Conv1D(4, 2),\n        layers.BatchNormalization(),\n        layers.Dropout(0.2),\n       # layers.LeakyReLU(alpha=0.2),\n        \n        layers.Conv1D(8, 2),\n        layers.BatchNormalization(),\n        layers.Dropout(0.2),\n        \n        layers.Flatten(),\n        layers.Dense(2,activation='sigmoid'),\n    ],\n    name=\"student\",)\n    \n\n# Clone student for later comparison\nstudent_scratch = keras.models.clone_model(student)\n\n#compile STUDENT\nstudent_scratch.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint( sep='\\n')\nprint('STUDENT')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"student.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Teacher Model training","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\nteacher_history=teacher.fit(X_train,y_train,epochs=epoch,validation_data=(X_test,y_test),verbose=1)\nend_time = time.time()\nprint( sep='\\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Teacher Evaluation","metadata":{}},{"cell_type":"code","source":"teacher_loss, teacher_acc = teacher.evaluate(X_test, y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Teacher File as Keras","metadata":{}},{"cell_type":"code","source":"teacher.save(\"teacher_model.keras\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Teacher File as TFLite","metadata":{}},{"cell_type":"code","source":"# Export model\nteacher.export(\"teacher\") \n\n# Convert to a TFLite model\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"teacher\")\nmy_teacher_model = converter.convert()\n\nwith open(\"teacher.tflite\", \"wb\") as f:\n    f.write(my_teacher_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Student Model without KD Training","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\nstudent_scratch_history=student_scratch.fit(X_train,y_train,epochs=epoch,validation_data=(X_test,y_test),verbose=1)\nend_time = time.time()\nprint( sep='\\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate Student Scratch","metadata":{}},{"cell_type":"code","source":"student_scratch_loss, student_scratch_acc = student_scratch.evaluate(X_test, y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Student Scratch File as Keras","metadata":{}},{"cell_type":"code","source":"student_scratch.save(\"student_scratch_model.keras\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Student Scratch File as TFLite","metadata":{}},{"cell_type":"code","source":"# Export model\nstudent_scratch.export(\"student_scratch\") \n\n# Convert to a TFLite model\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"student_scratch\")\nmy_student_scratch_model = converter.convert()\n\nwith open(\"student_scratch.tflite\", \"wb\") as f:\n    f.write(my_student_scratch_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Knowledge Distillation\n## Construct distiller class","metadata":{}},{"cell_type":"code","source":"class Distiller(keras.Model):\n    def __init__(self, student, teacher):\n        super(Distiller, self).__init__()\n        self.teacher = teacher\n        self.student = student\n\n    def compile(\n        self,\n        optimizer,\n        metrics,\n        student_loss_fn,\n        distillation_loss_fn,\n        alpha=0.1,\n        temperature=3,\n    ):\n        \"\"\" Configure the distiller.\n\n        Args:\n            optimizer: Keras optimizer for the student weights\n            metrics: Keras metrics for evaluation\n            student_loss_fn: Loss function of difference between student\n                predictions and ground-truth\n            distillation_loss_fn: Loss function of difference between soft\n                student predictions and soft teacher predictions\n            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n            temperature: Temperature for softening probability distributions.\n                Larger temperature gives softer distributions.\n        \"\"\"\n        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n        self.student_loss_fn = student_loss_fn\n        self.distillation_loss_fn = distillation_loss_fn\n        self.alpha = alpha\n        self.temperature = temperature\n\n    def train_step(self, data):\n        # Unpack data\n        x, y = data\n\n        # Forward pass of teacher\n        teacher_predictions = self.teacher(x, training=False)\n\n        with tf.GradientTape() as tape:\n            # Forward pass of student\n            student_predictions = self.student(x, training=True)\n\n            # Compute losses\n            student_loss = self.student_loss_fn(y, student_predictions)\n            distillation_loss = self.distillation_loss_fn(\n                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n            )\n            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n\n        # Compute gradients\n        trainable_vars = self.student.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n\n        # Update weights\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n\n        # Update the metrics configured in `compile()`.\n        self.compiled_metrics.update_state(y, student_predictions)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update(\n            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n        )\n        return results\n\n    def test_step(self, data):\n        # Unpack the data\n        x, y = data\n\n        # Compute predictions\n        y_prediction = self.student(x, training=False)\n\n        # Calculate the loss\n        student_loss = self.student_loss_fn(y, y_prediction)\n\n        # Update the metrics.\n        self.compiled_metrics.update_state(y, y_prediction)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update({\"student_loss\": student_loss})\n        return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Initialize and compile distiller\ndistiller = Distiller(student=student, teacher=teacher)\ndistiller.compile(optimizer=keras.optimizers.Adam(),\nmetrics=['accuracy'],\nstudent_loss_fn= keras.losses.BinaryCrossentropy() ,\ndistillation_loss_fn=keras.losses.KLDivergence(),\nalpha=0.1,\ntemperature=10,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Distill Teacher to Student","metadata":{}},{"cell_type":"code","source":"print( sep='\\n')\nprint('DISTILL TEACHER TO STUDENT')\nstart_time = time.time()\nkd_history=distiller.fit(X_train, y_train, epochs=epoch, verbose=1, validation_data=(X_test,y_test))\nend_time = time.time()\nprint( sep='\\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate Distilled Student","metadata":{}},{"cell_type":"code","source":"distiller_evaluate_output = distiller.evaluate(X_test, y_test)\n\n#Sample output:\n#[<tf.Tensor: shape=(), dtype=float32, numpy=0.49883049726486206>,\n# {'accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9069767594337463>},\n# <tf.Tensor: shape=(), dtype=float32, numpy=0.15347284078598022>]\n\n# The first element in the list is the student loss.\n# We use .numpy() to get the numerical value.\ndistiller_student_loss = distiller_evaluate_output[0].numpy()\n\n# The second element is a dictionary. We access the 'accuracy' key\n# and then get its numpy value.\ndistiller_accuracy = distiller_evaluate_output[1]['accuracy'].numpy()\n\n# The third element is the total combined loss.\ndistiller_total_loss = distiller_evaluate_output[2].numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Distilled Student File as Keras","metadata":{}},{"cell_type":"code","source":"distiller.student.save(\"distilled_model.keras\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Distilled Student File as TFLite","metadata":{}},{"cell_type":"code","source":"# Export model\ndistiller.student.export(\"distiller\") \n\n# Convert to a TFLite model\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"distiller\")\nmy_distiller_model = converter.convert()\n\nwith open(\"distiller.tflite\", \"wb\") as f:\n    f.write(my_distiller_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # Plots of accuracy and loss ","metadata":{}},{"cell_type":"markdown","source":"## File Sizes","metadata":{}},{"cell_type":"code","source":"import os\n\noriginal_size = os.path.getsize(\"teacher_model.keras\") / 1024\noriginal_tflite_size = os.path.getsize(\"teacher.tflite\") / 1024\n\nstudent_scratch_size = os.path.getsize(\"student_scratch_model.keras\") / 1024\nstudent_scratch_tflite_size = os.path.getsize(\"student_scratch.tflite\") / 1024\n\ndistiller_size = os.path.getsize(\"distilled_model.keras\") / 1024\ndistiller_tflite_size = os.path.getsize(\"distiller.tflite\") / 1024\n\n\n\nprint(f\"Keras Original size: \\t\\t{original_size:.2f} KB\")\nprint(f\"TFLite Original size: \\t\\t{original_tflite_size:.2f} KB\")\n\nprint(f\"Keras Student Scratch size: \\t{student_scratch_size:.2f} KB\")\nprint(f\"TFLite Student Scratch size: \\t{student_scratch_tflite_size:.2f} KB\")\n\nprint(f\"Keras Distilled size: \\t\\t{distiller_size:.2f} KB\")\nprint(f\"TFLite Distilled size: \\t\\t{distiller_tflite_size:.2f} KB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating TFLite","metadata":{}},{"cell_type":"code","source":"def evaluate_tflite_model(tflite_path, X_test, y_test):\n    import numpy as np\n    import tensorflow as tf\n\n    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    input_index = input_details[0]['index']\n    output_index = output_details[0]['index']\n\n    correct = 0\n    y_pred=[]\n    y_true=[]\n    for i in range(len(X_test)):\n        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n\n        interpreter.set_tensor(input_index, input_data)\n        interpreter.invoke()\n        output = interpreter.get_tensor(output_index)  # shape (1, 2)\n\n        predicted = np.argmax(output[0])       # pick class with highest sigmoid score\n        actual = np.argmax(y_test[i])          # one-hot to label\n        y_pred.append(predicted)\n        y_true.append(actual)\n\n        if predicted == actual:\n            correct += 1\n\n    accuracy = correct / len(X_test)\n    print(f\"TFLite model accuracy: {accuracy * 100:.2f}%\")\n    return accuracy, y_true, y_pred","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher_tflite_acc, teacher_tflite_y_true, teacher_tflite_y_pred= evaluate_tflite_model(\"teacher.tflite\", X_test, y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"student_scratch_tflite_acc, student_scratch_y_true, student_scratch_y_pred= evaluate_tflite_model(\"student_scratch.tflite\", X_test, y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"distiller_tflite_acc, distiller_tflite_y_true, distiller_tflite_y_pred= evaluate_tflite_model(\"distiller.tflite\", X_test, y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Accuracy and loss of teacher model","metadata":{}},{"cell_type":"code","source":"def plotLearningCurve(history,epochs):\n  epochRange = range(1,epochs+1)\n  plt.plot(epochRange,history.history['accuracy'])\n  plt.plot(epochRange,history.history['val_accuracy'])\n  plt.title('Model Accuracy')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend(['Train','Validation'],loc='lower right')\n  plt.grid(visible=True)\n  plt.show()\n\n  plt.plot(epochRange,history.history['loss'])\n  plt.plot(epochRange,history.history['val_loss'])\n  plt.title('Model Loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['Train','Validation'],loc='upper right')\n  plt.grid(visible=True)\n  plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotLearningCurve(teacher_history,epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Students functions","metadata":{}},{"cell_type":"code","source":"def plotKDCurveD(history,epochs):\n  epochRange = range(1,epochs+1)\n\n  #dict_keys(['accuracy', 'distillation_loss', 'loss', 'student_loss', 'val_loss', 'val_student_loss'])\n  plt.plot(epochRange,history.history['accuracy'])\n  plt.title('Model Accuracy')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend(['Train'],loc='lower right')\n  plt.grid(visible=True)\n  plt.show()\n\n  plt.plot(epochRange,history.history['distillation_loss'])  \n  plt.plot(epochRange,history.history['loss'])\n  plt.plot(epochRange,history.history['val_loss'])\n  plt.plot(epochRange,history.history['student_loss'])\n  plt.plot(epochRange,history.history['val_student_loss'])\n  plt.title('Model Loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['distillation_loss','loss','val_loss','student_loss','val_student_loss'],loc='upper right')\n  plt.grid(visible=True)\n  plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plotting Student scratch Model( without KD)","metadata":{}},{"cell_type":"code","source":"plotLearningCurve(student_scratch_history,epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Student knowledge distilled accuracy and loss","metadata":{}},{"cell_type":"code","source":"plotKDCurveD(kd_history,epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Function plotting two models","metadata":{}},{"cell_type":"code","source":"def plotKDCurveProf(his,tHis,epochs):\n  epochRange = range(1,epochs+1)\n  plt.plot(epochRange,tHis.history['accuracy'])\n  plt.plot(epochRange,tHis.history['val_accuracy'])\n  plt.plot(epochRange,his.history['accuracy'])\n  #plt.plot(epochRange,his.history['val_accuracy']) #KD has no val_accuracy\n\n  plt.title('Model Accuracy')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend(['T_train','T_val','KD_train','KD_val'],loc='lower right')\n  plt.grid(visible=True)\n  plt.show()\n\n\n  plt.plot(epochRange,tHis.history['loss'])\n  plt.plot(epochRange,tHis.history['val_loss'])\n  plt.plot(epochRange,his.history['student_loss'])\n  plt.plot(epochRange,his.history['val_student_loss'])\n  plt.title('Model Loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['T_train','T_val','KD_train','KD_val'],loc='upper right')\n  plt.grid(visible=True)\n  plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Student with KD Vs Teacher Accuracy and loss","metadata":{}},{"cell_type":"code","source":"plotKDCurveProf(kd_history,teacher_history,epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Student with KD Vs Student without Kd Accuracy and loss","metadata":{}},{"cell_type":"code","source":"plotKDCurveProf(kd_history,student_scratch_history,epoch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Weights and Parameters","metadata":{}},{"cell_type":"code","source":"#==========================================================================\n#Function for counting weights that were zeroed\n#==========================================================================\ndef count_zeros(model):\n    total = 0\n    zeros = 0\n    for layer in model.layers:\n        weights = layer.get_weights()\n        for w in weights:\n            total += w.size\n            zeros += np.sum(w == 0)\n    print(f\"Total weights: {total}\")\n    print(f\"Zero weights: {zeros}\")\n    print(f\"Sparsity: {100 * zeros / total:.2f}%\")\n    return total, zeros\n    \n#Print the performance\nprint(\"Teacher model:\")\nteacher_param_total, teacher_param_zeros = count_zeros(teacher)\n\n#Print the performance\nprint(\"\\n\\nUndistilled Student:\")\nstudent_scratch_param_total, student_scratch_param_zeros = count_zeros(student_scratch)\n\n#Print the performance\nprint(\"\\n\\nDistilled Student & stripped model:\")\ndistiller_std_param_total, distiller_std_param_zeros = count_zeros(distiller.student)\ndistiller_param_total, distiller_param_zeros = count_zeros(distiller)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Result Summary","metadata":{}},{"cell_type":"code","source":"print(\"Vals. \\t\\t\\t TM \\t\\t SM_scratch \\t SM\")\nprint(\"=\"*65)\nprint(\"Acc. (%%) \\t\\t %.2f \\t %.2f \\t\\t %.2f\"%(teacher_history.history['accuracy'][epoch-1]*100,student_scratch_history.history['accuracy'][epoch-1]*100,kd_history.history['accuracy'][epoch-1]*100))\nprint(\"Val. Acc. (%%) \\t\\t %.2f \\t\\t %.2f \\t\\t -\"%(teacher_history.history['val_accuracy'][epoch-1]*100,student_scratch_history.history['val_accuracy'][epoch-1]*100))\nprint(\"Loss. (%%) \\t\\t %.2f \\t\\t %.2f \\t\\t %.2f\"%(teacher_history.history['loss'][epoch-1]*100,student_scratch_history.history['loss'][epoch-1]*100,kd_history.history['loss'][epoch-1]*100))\nprint(\"Val. Loss. (%%) \\t\\t %.2f \\t\\t %.2f \\t\\t %.2f\"%(teacher_history.history['val_loss'][epoch-1]*100,student_scratch_history.history['val_loss'][epoch-1]*100,kd_history.history['val_loss'][epoch-1]*100))\nprint(\"=\"*65)\nprint(\"Keras size (kb)\\t\\t%.2f\\t\\t%.2f\\t\\t%.2f\"%(original_size,student_scratch_size,distiller_size))\nprint(\"tflite size (kb)\\t%.2f\\t\\t%.2f\\t\\t%.2f\"%(original_tflite_size,student_scratch_tflite_size,distiller_tflite_size))\nprint(\"Acc. (tflite)(%%)\\t%.2f\\t\\t%.2f\\t\\t%.2f\"%(teacher_tflite_acc*100,student_scratch_tflite_acc*100,distiller_tflite_acc*100))\nprint(\"Total Weight\\t%d\\t\\t%d\\t\\t%d\"%(teacher_param_total, student_scratch_param_total, distiller_std_param_total))\nprint(\"Zero Weight\\t\\t%d\\t\\t%d\\t\\t%d\"%(teacher_param_zeros, student_scratch_param_zeros, distiller_std_param_zeros))\nprint(\"Sparsity\\t\\t%.2f\\t\\t%.2f\\t\\t%.2f\"%(teacher_param_zeros/teacher_param_total*100, student_scratch_param_zeros/student_scratch_param_total*100, distiller_std_param_zeros/distiller_std_param_total*100))\nprint(\"=\"*65)\nprint(\"*No. of Weights in SM with Distiller Wrapper %d\"%(distiller_param_total))\nprint(\"*No. of Weight with Zero Weight in SM with Distiller Wrapper %d\"%(distiller_param_zeros))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}